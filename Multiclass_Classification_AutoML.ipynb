{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml\n",
    "from evalml import AutoMLSearch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Load the Iris dataset\n",
    "# iris = load_iris()\n",
    "# # iris\n",
    "# X, y = iris.data, iris.target\n",
    "data=sns.load_dataset('iris')\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "setosa        50\n",
       "versicolor    50\n",
       "virginica     50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into training and testing sets\n",
    "X, y = data.drop(columns=['species']), data['species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "22            4.6          3.6           1.0          0.2\n",
       "15            5.7          4.4           1.5          0.4\n",
       "65            6.7          3.1           4.4          1.4\n",
       "11            4.8          3.4           1.6          0.2\n",
       "42            4.4          3.2           1.3          0.2\n",
       "..            ...          ...           ...          ...\n",
       "71            6.1          2.8           4.0          1.3\n",
       "106           4.9          2.5           4.5          1.7\n",
       "14            5.8          4.0           1.2          0.2\n",
       "92            5.8          2.6           4.0          1.2\n",
       "102           7.1          3.0           5.9          2.1\n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tHigh coefficient of variation (cv >= 0.5) within cross validation scores.\n",
      "\tMode Baseline Multiclass Classification Pipeline may not perform as estimated on unseen data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'Random Forest Classifier w/ Label Encoder + Imputer + RF Classifier Select From Model': 2.130824327468872,\n",
       "  'Total time of batch': 2.8214614391326904},\n",
       " 2: {'LightGBM Classifier w/ Label Encoder + Imputer + Select Columns Transformer': 0.7162966728210449,\n",
       "  'Extra Trees Classifier w/ Label Encoder + Imputer + Select Columns Transformer': 1.1966769695281982,\n",
       "  'Elastic Net Classifier w/ Label Encoder + Imputer + Standard Scaler + Select Columns Transformer': 0.4893350601196289,\n",
       "  'XGBoost Classifier w/ Label Encoder + Imputer + Select Columns Transformer': 0.8897912502288818,\n",
       "  'Logistic Regression Classifier w/ Label Encoder + Imputer + Standard Scaler + Select Columns Transformer': 8.373318910598755,\n",
       "  'Total time of batch': 15.59993314743042},\n",
       " 3: {'Extra Trees Classifier w/ Label Encoder + Imputer + Select Columns Transformer': 1.2509610652923584,\n",
       "  'Random Forest Classifier w/ Label Encoder + Imputer + Select Columns Transformer': 5.538467645645142,\n",
       "  'Elastic Net Classifier w/ Label Encoder + Imputer + Standard Scaler + Select Columns Transformer': 0.48163700103759766,\n",
       "  'Total time of batch': 31.482455253601074}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the objective to optimize (e.g., 'log loss' for multiclass classification)\n",
    "objective = 'log loss multiclass'\n",
    "\n",
    "# Create and run the AutoML search with hyperparameter tuning\n",
    "automl = AutoMLSearch(X_train=X_train, y_train=y_train, problem_type='multiclass', objective=objective, max_iterations=20)\n",
    "automl.search()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>search_order</th>\n",
       "      <th>ranking_score</th>\n",
       "      <th>mean_cv_score</th>\n",
       "      <th>standard_deviation_cv_score</th>\n",
       "      <th>percent_better_than_baseline</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>Elastic Net Classifier w/ Label Encoder + Impu...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.107178</td>\n",
       "      <td>0.107178</td>\n",
       "      <td>0.024966</td>\n",
       "      <td>99.548320</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Extra Trees Classifier w/ Label Encoder + Impu...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.133809</td>\n",
       "      <td>0.133809</td>\n",
       "      <td>0.023493</td>\n",
       "      <td>99.436090</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>Random Forest Classifier w/ Label Encoder + Im...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.146581</td>\n",
       "      <td>0.146581</td>\n",
       "      <td>0.056838</td>\n",
       "      <td>99.382264</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>Random Forest Classifier w/ Label Encoder + Im...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.180150</td>\n",
       "      <td>0.180150</td>\n",
       "      <td>0.101761</td>\n",
       "      <td>99.240793</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>Logistic Regression Classifier w/ Label Encode...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.206716</td>\n",
       "      <td>0.206716</td>\n",
       "      <td>0.025983</td>\n",
       "      <td>99.128839</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>LightGBM Classifier w/ Label Encoder + Imputer...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.227084</td>\n",
       "      <td>0.227084</td>\n",
       "      <td>0.106245</td>\n",
       "      <td>99.043002</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>XGBoost Classifier w/ Label Encoder + Imputer ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.265383</td>\n",
       "      <td>0.265383</td>\n",
       "      <td>0.032913</td>\n",
       "      <td>98.881598</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>Mode Baseline Multiclass Classification Pipeline</td>\n",
       "      <td>0</td>\n",
       "      <td>23.728738</td>\n",
       "      <td>23.728738</td>\n",
       "      <td>0.520245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                      pipeline_name  search_order  \\\n",
       "0    9  Elastic Net Classifier w/ Label Encoder + Impu...             9   \n",
       "2    3  Extra Trees Classifier w/ Label Encoder + Impu...             3   \n",
       "7   17  Random Forest Classifier w/ Label Encoder + Im...            17   \n",
       "14   1  Random Forest Classifier w/ Label Encoder + Im...             1   \n",
       "16   6  Logistic Regression Classifier w/ Label Encode...             6   \n",
       "17   2  LightGBM Classifier w/ Label Encoder + Imputer...             2   \n",
       "18   5  XGBoost Classifier w/ Label Encoder + Imputer ...             5   \n",
       "19   0   Mode Baseline Multiclass Classification Pipeline             0   \n",
       "\n",
       "    ranking_score  mean_cv_score  standard_deviation_cv_score  \\\n",
       "0        0.107178       0.107178                     0.024966   \n",
       "2        0.133809       0.133809                     0.023493   \n",
       "7        0.146581       0.146581                     0.056838   \n",
       "14       0.180150       0.180150                     0.101761   \n",
       "16       0.206716       0.206716                     0.025983   \n",
       "17       0.227084       0.227084                     0.106245   \n",
       "18       0.265383       0.265383                     0.032913   \n",
       "19      23.728738      23.728738                     0.520245   \n",
       "\n",
       "    percent_better_than_baseline  high_variance_cv  \\\n",
       "0                      99.548320             False   \n",
       "2                      99.436090             False   \n",
       "7                      99.382264             False   \n",
       "14                     99.240793             False   \n",
       "16                     99.128839             False   \n",
       "17                     99.043002             False   \n",
       "18                     98.881598             False   \n",
       "19                      0.000000              True   \n",
       "\n",
       "                                           parameters  \n",
       "0   {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "2   {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "7   {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "14  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "16  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "17  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "18  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "19  {'Label Encoder': {'positive_label': None}, 'B...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the ranking of pipelines\n",
    "pipeline_rankings = automl.rankings\n",
    "pipeline_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline = MulticlassClassificationPipeline(component_graph={'Label Encoder': ['Label Encoder', 'X', 'y'], 'Imputer': ['Imputer', 'X', 'Label Encoder.y'], 'Standard Scaler': ['Standard Scaler', 'Imputer.x', 'Label Encoder.y'], 'Select Columns Transformer': ['Select Columns Transformer', 'Standard Scaler.x', 'Label Encoder.y'], 'Elastic Net Classifier': ['Elastic Net Classifier', 'Select Columns Transformer.x', 'Label Encoder.y']}, parameters={'Label Encoder':{'positive_label': None}, 'Imputer':{'categorical_impute_strategy': 'most_frequent', 'numeric_impute_strategy': 'knn', 'boolean_impute_strategy': 'most_frequent', 'categorical_fill_value': None, 'numeric_fill_value': None, 'boolean_fill_value': None}, 'Select Columns Transformer':{'columns': ['petal_length', 'petal_width']}, 'Elastic Net Classifier':{'penalty': 'elasticnet', 'C': 8.474044870453413, 'l1_ratio': 0.6235636967859725, 'n_jobs': -1, 'multi_class': 'auto', 'solver': 'saga'}}, random_seed=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best pipeline\n",
    "best_pipeline = automl.best_pipeline\n",
    "best_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************************************************************************\n",
      "* Elastic Net Classifier w/ Label Encoder + Imputer + Standard Scaler + Select Columns Transformer *\n",
      "****************************************************************************************************\n",
      "\n",
      "Problem Type: multiclass\n",
      "Model Family: Linear\n",
      "\n",
      "Pipeline Steps\n",
      "==============\n",
      "1. Label Encoder\n",
      "\t * positive_label : None\n",
      "2. Imputer\n",
      "\t * categorical_impute_strategy : most_frequent\n",
      "\t * numeric_impute_strategy : knn\n",
      "\t * boolean_impute_strategy : most_frequent\n",
      "\t * categorical_fill_value : None\n",
      "\t * numeric_fill_value : None\n",
      "\t * boolean_fill_value : None\n",
      "3. Standard Scaler\n",
      "4. Select Columns Transformer\n",
      "\t * columns : ['petal_length', 'petal_width']\n",
      "5. Elastic Net Classifier\n",
      "\t * penalty : elasticnet\n",
      "\t * C : 8.474044870453413\n",
      "\t * l1_ratio : 0.6235636967859725\n",
      "\t * n_jobs : -1\n",
      "\t * multi_class : auto\n",
      "\t * solver : saga\n",
      "\n",
      "Training\n",
      "========\n",
      "Training for multiclass problems.\n",
      "Total training time (including CV): 0.5 seconds\n",
      "\n",
      "Cross Validation\n",
      "----------------\n",
      "             Log Loss Multiclass  MCC Multiclass  AUC Weighted  AUC Macro  AUC Micro  Precision Weighted  Precision Macro  Precision Micro  F1 Weighted  F1 Macro  F1 Micro  Balanced Accuracy Multiclass  Accuracy Multiclass # Training # Validation\n",
      "0                          0.113           0.925         0.996      0.996      0.997               0.950            0.949            0.950        0.950     0.949     0.950                         0.949                0.950         80           40\n",
      "1                          0.129           0.888         0.996      0.996      0.997               0.926            0.928            0.925        0.925     0.926     0.925                         0.925                0.925         80           40\n",
      "2                          0.080           0.963         1.000      1.000      0.999               0.977            0.976            0.975        0.975     0.975     0.975                         0.976                0.975         80           40\n",
      "mean                       0.107           0.926         0.998      0.997      0.998               0.951            0.951            0.950        0.950     0.950     0.950                         0.950                0.950          -            -\n",
      "std                        0.025           0.038         0.002      0.002      0.001               0.025            0.024            0.025        0.025     0.025     0.025                         0.026                0.025          -            -\n",
      "coef of var                0.233           0.041         0.002      0.002      0.001               0.027            0.026            0.026        0.026     0.026     0.026                         0.027                0.026          -            -\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best pipeline and summarize the results\n",
    "best_pipeline = automl.best_pipeline\n",
    "automl.describe_pipeline(automl.rankings.iloc[0][\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the best pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best pipeline\n",
    "best_pipeline.save(\"Multi_Cassification_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the saved model in order to do prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=automl.load('Multi_Cassification_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73     versicolor\n",
       "18         setosa\n",
       "118     virginica\n",
       "78     versicolor\n",
       "76     versicolor\n",
       "31         setosa\n",
       "64     versicolor\n",
       "141     virginica\n",
       "68     versicolor\n",
       "82     versicolor\n",
       "110     virginica\n",
       "12         setosa\n",
       "36         setosa\n",
       "9          setosa\n",
       "19         setosa\n",
       "56     versicolor\n",
       "104     virginica\n",
       "69     versicolor\n",
       "55     versicolor\n",
       "132     virginica\n",
       "29         setosa\n",
       "127     virginica\n",
       "26         setosa\n",
       "128     virginica\n",
       "131     virginica\n",
       "145     virginica\n",
       "108     virginica\n",
       "143     virginica\n",
       "45         setosa\n",
       "30         setosa\n",
       "Name: species, dtype: category\n",
       "Categories (3, object): ['setosa', 'versicolor', 'virginica']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = final_model.predict(X_test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True_result</th>\n",
       "      <th>Predicted_result</th>\n",
       "      <th>Correct_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    True_result Predicted_result  Correct_result\n",
       "73   versicolor       versicolor               1\n",
       "18       setosa           setosa               1\n",
       "118   virginica        virginica               1\n",
       "78   versicolor       versicolor               1\n",
       "76   versicolor       versicolor               1\n",
       "31       setosa           setosa               1\n",
       "64   versicolor       versicolor               1\n",
       "141   virginica        virginica               1\n",
       "68   versicolor       versicolor               1\n",
       "82   versicolor       versicolor               1\n",
       "110   virginica        virginica               1\n",
       "12       setosa           setosa               1\n",
       "36       setosa           setosa               1\n",
       "9        setosa           setosa               1\n",
       "19       setosa           setosa               1\n",
       "56   versicolor       versicolor               1\n",
       "104   virginica        virginica               1\n",
       "69   versicolor       versicolor               1\n",
       "55   versicolor       versicolor               1\n",
       "132   virginica        virginica               1\n",
       "29       setosa           setosa               1\n",
       "127   virginica        virginica               1\n",
       "26       setosa           setosa               1\n",
       "128   virginica        virginica               1\n",
       "131   virginica        virginica               1\n",
       "145   virginica        virginica               1\n",
       "108   virginica        virginica               1\n",
       "143   virginica        virginica               1\n",
       "45       setosa           setosa               1\n",
       "30       setosa           setosa               1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred=pd.DataFrame({'True_result': y_test, 'Predicted_result':y_pred})\n",
    "df_pred['Correct_result']=np.where(df_pred['True_result']==df_pred['Predicted_result'],1,0)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    30\n",
       "Name: Correct_result, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred['Correct_result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ObjectiveNotFoundError",
     "evalue": "accuracy is not a valid Objective! Use evalml.objectives.get_all_objective_names() to get a list of all valid objective names. ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mObjectiveNotFoundError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the predictions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m classification_report \u001b[38;5;241m=\u001b[39m \u001b[43mbest_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjectives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog loss multiclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# print(f\"Classification Report:\\n{classification_report}\")\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report)\n",
      "File \u001b[1;32mc:\\Users\\zeesh\\anaconda3\\envs\\forecating_env\\lib\\site-packages\\evalml\\pipelines\\classification_pipeline.py:176\u001b[0m, in \u001b[0;36mClassificationPipeline.score\u001b[1;34m(self, X, y, objectives, X_train, y_train)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate model performance on objectives.\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03m    dict: Ordered dictionary of objective scores.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    175\u001b[0m y \u001b[38;5;241m=\u001b[39m infer_feature_types(y)\n\u001b[1;32m--> 176\u001b[0m objectives \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_objectives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjectives\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_targets(y)\n",
      "File \u001b[1;32mc:\\Users\\zeesh\\anaconda3\\envs\\forecating_env\\lib\\site-packages\\evalml\\pipelines\\pipeline_base.py:809\u001b[0m, in \u001b[0;36mPipelineBase.create_objectives\u001b[1;34m(objectives)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m objective \u001b[38;5;129;01min\u001b[39;00m objectives:\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    808\u001b[0m         objective_instances\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 809\u001b[0m             \u001b[43mget_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[0;32m    810\u001b[0m         )\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ObjectiveCreationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    812\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobjective\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as a string in pipeline.score. Instantiate first and then add it to the list of objectives.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\zeesh\\anaconda3\\envs\\forecating_env\\lib\\site-packages\\evalml\\objectives\\utils.py:172\u001b[0m, in \u001b[0;36mget_objective\u001b[1;34m(objective, return_instance, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf parameter objective is not a string, it must be an instance of ObjectiveBase!\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    170\u001b[0m     )\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m objective\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_objectives_dict:\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ObjectiveNotFoundError(\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobjective\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid Objective! \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse evalml.objectives.get_all_objective_names() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto get a list of all valid objective names. \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m objective_class \u001b[38;5;241m=\u001b[39m all_objectives_dict[objective\u001b[38;5;241m.\u001b[39mlower()]\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_instance:\n",
      "\u001b[1;31mObjectiveNotFoundError\u001b[0m: accuracy is not a valid Objective! Use evalml.objectives.get_all_objective_names() to get a list of all valid objective names. "
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the predictions\n",
    "classification_report = best_pipeline.score(X_test, y_test, objectives=['log loss multiclass', 'accuracy'])\n",
    "# print(f\"Classification Report:\\n{classification_report}\")\n",
    "print(classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecating_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
